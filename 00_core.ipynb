{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7556d9ab-e3db-4bf5-b123-50cc4fb9b275",
   "metadata": {},
   "source": [
    "# Download science magazine articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad826c-8813-418c-94fe-2164b6abe6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp scidown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580a3a4-4b55-43d1-a69d-703f597b58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73ff90-086d-4b03-9f18-1c4128bcbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_science_pdf_urls_from_toc_page(toc_url, return_dois=False):\n",
    "    \"\"\"\n",
    "    Given a TOC in the form 'https://www.science.org/toc/science//377/6609'\n",
    "    returns a list of links to every pdf in the page with a DOI.\n",
    "    if `return_dois`, return a list of DOIs instead of web links\n",
    "    \"\"\"\n",
    "    reqs = requests.get(toc_url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "    doi_list = []\n",
    "    for link in soup.find_all('a'):\n",
    "        href_link = link.get('href')\n",
    "        if '/doi/epdf/' in href_link:\n",
    "            split_link = href_link.split('/')\n",
    "            #manually extract the DOI from the link\n",
    "            doi = split_link[-2] + '/' + split_link[-1]\n",
    "            doi_list.append(doi)\n",
    "\n",
    "    if return_dois:\n",
    "        return(doi_list)\n",
    "    else:\n",
    "        urls_list = ['https://www.science.org/doi/pdf/'+ doi + '?download=true' for doi in doi_list]\n",
    "        return(urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9306be6-c890-46cf-b186-87dcde4a0e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue URL for this volume and issue is: https://www.science.org/toc/science/377/6609\n",
      "Some links to pdfs in this issue\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.science.org/doi/pdf/10.1126/science.ade5003?download=true',\n",
       " 'https://www.science.org/doi/pdf/10.1126/science.ade5537?download=true',\n",
       " 'https://www.science.org/doi/pdf/10.1126/science.ade5539?download=true']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "VOLUME = 377\n",
    "ISSUE = 6609\n",
    "\n",
    "base_url = 'https://www.science.org/toc/science' \n",
    "issue_url = '/'.join([base_url, str(VOLUME), str(ISSUE)])\n",
    "print('Issue URL for this volume and issue is:', issue_url)\n",
    "\n",
    "urls_list = extract_science_pdf_urls_from_toc_page(issue_url)\n",
    "\n",
    "print('Some links to pdfs in this issue')\n",
    "urls_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14a6f3-bb7e-4a1e-a21d-0e502ed17606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_wait(directory, timeout, nfiles=None):\n",
    "    \"\"\"\n",
    "    Wait for downloads to finish with a specified timeout.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    directory : str\n",
    "        The path to the folder where the files will be downloaded.\n",
    "    timeout : int\n",
    "        How many seconds to wait until timing out.\n",
    "    nfiles : int, defaults to None\n",
    "        If provided, also wait for the expected number of files.\n",
    "\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import os\n",
    "    \n",
    "    seconds = 0\n",
    "    dl_wait = True\n",
    "    while dl_wait and seconds < timeout:\n",
    "        time.sleep(2)\n",
    "        dl_wait = False\n",
    "        files = os.listdir(directory)\n",
    "        if nfiles and len(files) != nfiles:\n",
    "            dl_wait = True\n",
    "\n",
    "        for fname in files:\n",
    "            dl_wait = False\n",
    "            #if any file in list is temporary, wait!\n",
    "            if fname.endswith('.crdownload'):\n",
    "                dl_wait = True\n",
    "\n",
    "        seconds += 1\n",
    "    return seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94608195-7be7-41d0-95db-c1452881cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_pdfs_from_list_of_urls(list_of_urls, download_path = '~/Downloads/'):\n",
    "    \"\"\"\n",
    "    Download pdfs from a given list of pdf urls.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    list_of_urls : list of str\n",
    "        A list of string paths to each pdf.\n",
    "    download_path : str\n",
    "        Path to where pdfs will be downloaded.\n",
    "\n",
    "    \"\"\"\n",
    "    from selenium import webdriver\n",
    "    from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "    import os, sys, time\n",
    "    \n",
    "    #fix path in case path contains ~\n",
    "    download_path = os.path.expanduser(download_path)\n",
    "\n",
    "    if not os.path.isdir(download_path):\n",
    "        sys.exit('Download path does not exist')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option('prefs', {\n",
    "        \"download.default_directory\": download_path, #Change default directory for downloads\n",
    "        \"download.prompt_for_download\": False, #To auto download the file\n",
    "        \"download.directory_upgrade\": True,\n",
    "        \"safebrowsing.enabled\": True,\n",
    "        \"plugins.always_open_pdf_externally\": False #It will not show PDF directly in chrome\n",
    "    })\n",
    "    # options.add_argument(\"--headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "\n",
    "    for url in list_of_urls:\n",
    "        driver.get(url)\n",
    "\n",
    "    download_wait(download_path, timeout=10, nfiles=len(list_of_urls))\n",
    "    \n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bbdc9e-3b16-4ee8-b61f-37a08847ede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ck/tks_cc713yz3zfbr7tn7njgr0000gq/T/ipykernel_26882/748488647.py:35: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "# Testing how to download 1 pdf file\n",
    "download_pdfs_from_list_of_urls(urls_list[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f2c94b-2402-4f77-ab44-76ec72200f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_extra_page(path_to_pdf):\n",
    "    \"\"\"\n",
    "    Removes last page from a pdf\n",
    "    Saves on top of same pdf\n",
    "    \"\"\"\n",
    "    from PyPDF2 import PdfWriter, PdfReader\n",
    "    \n",
    "    infile = PdfReader(path_to_pdf, 'rb')\n",
    "    output = PdfWriter()\n",
    "\n",
    "    #loop over all pages except last\n",
    "    for i in range(len(infile.pages)-1):\n",
    "        p = infile.pages[i] \n",
    "        output.add_page(p)\n",
    "\n",
    "    with open(path_to_pdf, 'wb') as f:\n",
    "        output.write(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589d6f52-0b63-42e5-9a39-f9876b11cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pdfs(pdf_paths_list, final_pdf_location):\n",
    "    from PyPDF2 import PdfMerger\n",
    "    import os\n",
    "\n",
    "    merger = PdfMerger()\n",
    "\n",
    "    for pdf in pdf_paths_list:\n",
    "        merger.append(pdf)\n",
    "\n",
    "    if not final_pdf_location.endswith(pdf):\n",
    "        suffix = '.pdf'\n",
    "        os.path.join(final_pdf_location + suffix)\n",
    "\n",
    "    merger.write(final_pdf_location)\n",
    "    merger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58eb68a-3a34-44c0-92c3-6a11ee486037",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOLUME = 377\n",
    "ISSUE = 6609\n",
    "FINAL_DIR = '/Users/pablodamasceno/Downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6b504-b39e-4050-b72d-1b0d304a30dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary dir in:  /tmp/tmpn68yj5ua\n",
      "Issue URL for this volume and issue is: https://www.science.org/toc/science/377/6609\n",
      "Downloading  39  PDFs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ck/tks_cc713yz3zfbr7tn7njgr0000gq/T/ipykernel_26882/748488647.py:35: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download has finished.\n",
      "Removing extra pages...\n",
      "Extra pages removed.\n",
      "Combining pdfs...\n",
      "Final PDF created.\n",
      "Removing temporary directory...\n",
      "Directory removed. Enjoy your science magazine at:  /Users/pablodamasceno/Downloads/377_6609.pdf\n"
     ]
    }
   ],
   "source": [
    "#create temp dir\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "tempdir = tempfile.mkdtemp(dir='/tmp')\n",
    "\n",
    "print('Creating temporary dir in: ', str(tempdir))\n",
    "\n",
    "base_url = 'https://www.science.org/toc/science' \n",
    "issue_url = '/'.join([base_url, str(VOLUME), str(ISSUE)])\n",
    "print('Issue URL for this volume and issue is:', issue_url)\n",
    "\n",
    "urls_list = extract_science_pdf_urls_from_toc_page(issue_url)\n",
    "dois_list = extract_science_pdf_urls_from_toc_page(issue_url, return_dois=True)\n",
    "\n",
    "print('Downloading ', str(len(urls_list)), ' PDFs...')\n",
    "download_pdfs_from_list_of_urls(list_of_urls=urls_list, download_path=tempdir)\n",
    "print('Download has finished.')\n",
    "\n",
    "print('Removing extra pages...')\n",
    "list_of_filenames = os.listdir(tempdir)\n",
    "\n",
    "dois_list = extract_science_pdf_urls_from_toc_page(issue_url, return_dois=True)\n",
    "\n",
    "ordered_filenames = [os.path.join(tempdir, 'science.' + doi[16:] + '.pdf') for doi in dois_list]\n",
    "\n",
    "for name in list_of_filenames:\n",
    "    filepath = os.path.join(tempdir, name)\n",
    "    remove_extra_page(filepath)\n",
    "print('Extra pages removed.')\n",
    "\n",
    "print('Combining pdfs...')\n",
    "\n",
    "FINAL_PDF_LOCATION = os.path.join(FINAL_DIR, str(VOLUME)+'_'+str(ISSUE)+'.pdf')\n",
    "merge_pdfs(ordered_filenames, final_pdf_location=FINAL_PDF_LOCATION)\n",
    "print('Final PDF created.')\n",
    "\n",
    "print('Removing temporary directory...')\n",
    "shutil.rmtree(tempdir)\n",
    "print('Directory removed. Enjoy your science magazine at: ', str(FINAL_PDF_LOCATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aaa07e-b9d9-4271-9908-b9cb647a9948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ee790-8a57-42bc-a72e-6a6e8889fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea1d00-e1d6-4c37-b28a-54d7a6cfd7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
